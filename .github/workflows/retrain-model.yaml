# .github/workflows/retrain-model.yaml
# ìë™ ì¬í•™ìŠµ Pipeline: Drift ê°ì§€ ì‹œ ëª¨ë¸ ì¬í•™ìŠµ
##
# íŠ¸ë¦¬ê±°: 
#   - workflow_dispatch (ìˆ˜ë™ ë˜ëŠ” ì™¸ë¶€ API í˜¸ì¶œ)
#   - Prometheus Alert â†’ Webhook â†’ GitHub API

name: Retrain Model on Drift

on:
  workflow_dispatch:
    inputs:
      user_id:
        description: 'User ID that triggered retrain'
        required: true
        default: 'user01'
      drift_score:
        description: 'Drift score that triggered retrain'
        required: true
        default: '0.5'
      drift_reason:
        description: 'Reason for drift (MAE/R2)'
        required: false
        default: 'MAE threshold exceeded'

env:
  PYTHON_VERSION: '3.9'
  AWS_REGION: ap-northeast-2
  MLFLOW_TRACKING_URI: http://mlflow-server-service.mlflow-system.svc.cluster.local:5000
  S3_BUCKET: mlops-training-${{ github.event.inputs.user_id }}

jobs:
  # ============================================================
  # Job 1: ë°ì´í„° ì¤€ë¹„
  # ============================================================
  prepare-data:
    name: Prepare Training Data
    runs-on: ubuntu-latest
    
    outputs:
      data_version: ${{ steps.data.outputs.version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install boto3 pandas scikit-learn pyarrow
      
      - name: Download and prepare data
        id: data
        run: |
          python -c "
          import boto3
          import pandas as pd
          from sklearn.datasets import fetch_california_housing
          from datetime import datetime
          import os
          
          # ë°ì´í„° ë²„ì „ ìƒì„±
          version = datetime.now().strftime('%Y%m%d_%H%M%S')
          print(f'Data version: {version}')
          
          # California Housing ë°ì´í„° (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” S3ì—ì„œ ë‹¤ìš´ë¡œë“œ)
          data = fetch_california_housing()
          df = pd.DataFrame(data.data, columns=data.feature_names)
          df['target'] = data.target
          
          # ë¡œì»¬ ì €ì¥
          os.makedirs('data', exist_ok=True)
          df.to_parquet(f'data/training_data_{version}.parquet', index=False)
          
          print(f'Data shape: {df.shape}')
          print(f'Saved to: data/training_data_{version}.parquet')
          
          # Output ì„¤ì •
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'version={version}\n')
          "
      
      - name: Upload data artifact
        uses: actions/upload-artifact@v4
        with:
          name: training-data
          path: data/
          retention-days: 7

  # ============================================================
  # Job 2: ëª¨ë¸ ì¬í•™ìŠµ
  # ============================================================
  retrain:
    name: Retrain Model
    runs-on: ubuntu-latest
    needs: prepare-data
    
    outputs:
      model_version: ${{ steps.train.outputs.model_version }}
      mae: ${{ steps.train.outputs.mae }}
      r2: ${{ steps.train.outputs.r2 }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install scikit-learn pandas numpy mlflow boto3 joblib
      
      - name: Download data artifact
        uses: actions/download-artifact@v4
        with:
          name: training-data
          path: data/
      
      - name: Train model
        id: train
        env:
          USER_ID: ${{ github.event.inputs.user_id }}
          DRIFT_SCORE: ${{ github.event.inputs.drift_score }}
        run: |
          python -c "
          import os
          import glob
          import pandas as pd
          import numpy as np
          from sklearn.model_selection import train_test_split
          from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
          from sklearn.metrics import mean_absolute_error, r2_score
          import joblib
          from datetime import datetime
          
          print('='*60)
          print('  Model Retraining Pipeline')
          print('='*60)
          print(f'User ID: {os.environ.get(\"USER_ID\", \"unknown\")}')
          print(f'Drift Score: {os.environ.get(\"DRIFT_SCORE\", \"N/A\")}')
          print()
          
          # ë°ì´í„° ë¡œë“œ
          data_files = glob.glob('data/*.parquet')
          if data_files:
              df = pd.read_parquet(data_files[0])
          else:
              from sklearn.datasets import fetch_california_housing
              data = fetch_california_housing()
              df = pd.DataFrame(data.data, columns=data.feature_names)
              df['target'] = data.target
          
          print(f'Data shape: {df.shape}')
          
          # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
          X = df.drop('target', axis=1)
          y = df['target']
          X_train, X_test, y_train, y_test = train_test_split(
              X, y, test_size=0.2, random_state=42
          )
          
          # ì—¬ëŸ¬ ëª¨ë¸ ì‹¤í—˜
          models = {
              'RandomForest': RandomForestRegressor(
                  n_estimators=100, 
                  max_depth=10, 
                  random_state=42,
                  n_jobs=-1
              ),
              'GradientBoosting': GradientBoostingRegressor(
                  n_estimators=100, 
                  max_depth=5, 
                  random_state=42
              )
          }
          
          best_model = None
          best_mae = float('inf')
          best_name = ''
          
          for name, model in models.items():
              print(f'Training {name}...')
              model.fit(X_train, y_train)
              
              predictions = model.predict(X_test)
              mae = mean_absolute_error(y_test, predictions)
              r2 = r2_score(y_test, predictions)
              
              print(f'  MAE: {mae:.4f}, RÂ²: {r2:.4f}')
              
              if mae < best_mae:
                  best_mae = mae
                  best_model = model
                  best_name = name
                  best_r2 = r2
          
          print()
          print(f'Best model: {best_name}')
          print(f'  MAE: {best_mae:.4f}')
          print(f'  RÂ²: {best_r2:.4f}')
          
          # ëª¨ë¸ ì €ì¥
          model_version = datetime.now().strftime('%Y%m%d_%H%M%S')
          os.makedirs('models', exist_ok=True)
          model_path = f'models/model_{model_version}.joblib'
          joblib.dump(best_model, model_path)
          print(f'Model saved: {model_path}')
          
          # GitHub Output
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'model_version={model_version}\n')
              f.write(f'mae={best_mae:.4f}\n')
              f.write(f'r2={best_r2:.4f}\n')
          "
      
      - name: Upload model artifact
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/
          retention-days: 30

  # ============================================================
  # Job 3: ëª¨ë¸ ê²€ì¦
  # ============================================================
  validate:
    name: Validate New Model
    runs-on: ubuntu-latest
    needs: retrain
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          pip install scikit-learn pandas numpy joblib
      
      - name: Download model artifact
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: models/
      
      - name: Validate model
        env:
          MAE: ${{ needs.retrain.outputs.mae }}
          R2: ${{ needs.retrain.outputs.r2 }}
        run: |
          python -c "
          import os
          import glob
          import joblib
          import numpy as np
          from sklearn.datasets import fetch_california_housing
          
          print('='*60)
          print('  Model Validation')
          print('='*60)
          
          # ë©”íŠ¸ë¦­ í™•ì¸
          mae = float(os.environ.get('MAE', '1.0'))
          r2 = float(os.environ.get('R2', '0.0'))
          
          print(f'MAE: {mae}')
          print(f'RÂ²: {r2}')
          
          # ì„ê³„ê°’ ê²€ì¦
          MAE_THRESHOLD = 0.50
          R2_THRESHOLD = 0.70
          
          passed = True
          
          if mae > MAE_THRESHOLD:
              print(f'âŒ MAE ({mae:.4f}) exceeds threshold ({MAE_THRESHOLD})')
              passed = False
          else:
              print(f'âœ… MAE ({mae:.4f}) is within threshold')
          
          if r2 < R2_THRESHOLD:
              print(f'âŒ RÂ² ({r2:.4f}) is below threshold ({R2_THRESHOLD})')
              passed = False
          else:
              print(f'âœ… RÂ² ({r2:.4f}) is above threshold')
          
          # ì¶”ë¡  í…ŒìŠ¤íŠ¸
          print()
          print('Running inference test...')
          
          model_files = glob.glob('models/*.joblib')
          if model_files:
              model = joblib.load(model_files[0])
              
              # ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¶”ë¡ 
              sample = np.array([[8.3252, 41.0, 6.984127, 1.023810, 322.0, 2.555556, 37.88, -122.23]])
              prediction = model.predict(sample)
              
              print(f'Sample prediction: {prediction[0]:.4f}')
              
              if prediction[0] > 0:
                  print('âœ… Inference test passed')
              else:
                  print('âŒ Inference test failed')
                  passed = False
          
          if passed:
              print()
              print('ğŸ‰ Model validation PASSED!')
          else:
              print()
              print('âŒ Model validation FAILED!')
              exit(1)
          "

  # ============================================================
  # Job 4: ë°°í¬ íŠ¸ë¦¬ê±°
  # ============================================================
  trigger-deploy:
    name: Trigger Deployment
    runs-on: ubuntu-latest
    needs: [retrain, validate]
    if: success()
    
    steps:
      - name: Trigger CD Pipeline
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.PAT_TOKEN }}
          event-type: model-retrained
          client-payload: |
            {
              "user_id": "${{ github.event.inputs.user_id }}",
              "model_version": "${{ needs.retrain.outputs.model_version }}",
              "mae": "${{ needs.retrain.outputs.mae }}",
              "r2": "${{ needs.retrain.outputs.r2 }}",
              "drift_score": "${{ github.event.inputs.drift_score }}",
              "triggered_by": "drift-retrain"
            }
      
      - name: Summary
        run: |
          echo "============================================================"
          echo "  Retrain Pipeline Complete"
          echo "============================================================"
          echo ""
          echo "ğŸ“Š Results:"
          echo "   User ID: ${{ github.event.inputs.user_id }}"
          echo "   Drift Score: ${{ github.event.inputs.drift_score }}"
          echo "   Model Version: ${{ needs.retrain.outputs.model_version }}"
          echo "   MAE: ${{ needs.retrain.outputs.mae }}"
          echo "   RÂ²: ${{ needs.retrain.outputs.r2 }}"
          echo ""
          echo "ğŸš€ Deployment triggered!"
          echo ""
          echo "ğŸ“Œ Next Steps:"
          echo "   1. CD Pipeline will build and deploy the new model"
          echo "   2. Monitor metrics in Grafana"
          echo "   3. Verify performance improvement"
